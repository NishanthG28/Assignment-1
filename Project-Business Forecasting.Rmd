---
title: "Project-Business Forecasting"
author: "ng765@scarletmail.rutgers.edu"
date: "2024-11-23"
output:
  html_document: default
---

```{r, echo=FALSE, results='asis'}
knitr::opts_chunk$set(fig.width = 10, fig.height = 6)
cat("Description of the Data
The dataset contains detailed information on reported crimes, categorized by type, location, and time. It includes columns such as:

Date: The date of the occurrence.
Time: The time of the occurrence.
Latitude and Longitude: Geographical coordinates of the incident.
Offense Category: The type of crime, such as larceny, vandalism, or burglary.
Violent/Property Crime Indicator: Classification of crimes as violent or property-related.
Domestic: Indicates if the crime was domestic in nature.
Total Incidents: Number of incidents reported for a specific category.
The data spans multiple years and includes seasonality, trend, and random components. By analyzing these elements, we aim to uncover patterns and develop reliable forecasting models to predict future crime occurrences.

Objective:
Using advanced time-series methods such as ARIMA, STL decomposition, and Holt-Winters, the analysis aims to identify the most accurate model for predicting crime trends in various categories, thus enabling actionable insights.")
cat("Importance: Accurately forecasting crime trends is vital for law enforcement, policymakers, and communities. By understanding the future trajectory of specific crime categories, stakeholders can proactively address challenges, optimize resource allocation, and implement preventive measures. This analysis supports data-driven decision-making, enhancing public safety and fostering community well-being.")
library(ggplot2)  
library(dplyr)    
library(tidyr)    
library(scales) 
library(lubridate)
library(forecast)
library(Metrics)
Crime <- read.csv("C:/Users/gadda/Downloads/cpd-incidents.csv")
Crimes_per_year <- aggregate(Crime$Year, by = list(Year = Crime$Year), FUN = length)
Crimes_per_year <- Crimes_per_year[order(Crimes_per_year$Year), ]
Crimes_per_year_ts <- ts(Crimes_per_year$x , start = min(Crimes_per_year$Year), frequency = 1)
plot(Crimes_per_year_ts, main = "Number of Crimes per Year", xlab = "Year", ylab = "Number of Crimes") 
cat(" We would cut the data at 2001\n") 

Crime <- Crime[Crime$Year >= 2000, ]
Crimes_per_year <- aggregate(Crime$Year, by = list(Year = Crime$Year), FUN = length)
Crimes_per_year <- Crimes_per_year[order(Crimes_per_year$Year), ]

Crimes_per_year_ts <- ts(Crimes_per_year$x , start = min(Crimes_per_year$Year), frequency = 1)
plot(Crimes_per_year_ts, main = "Number of Crimes per Year", xlab = "Year", ylab = "Number of Crimes") 

colselect <- c("Begin.Date.Of.Occurrence", "Begin.Time.Of.Occurrence", "Lat", "Lon",
               "Offense.Category", "Violent.Property", "domestic", "Total.Incidents")

cat("New column names to be applied\n")
colnames <- c("Date", "Time", "Lat", "Lon", "Cat", "VP", "Domestic", "Tot_Inc")


df <- Crime %>%
  select(all_of(colselect)) %>%
  rename_with(~ colnames)

df <- df %>%
  mutate(Date = as.Date(Date)) %>%
  arrange(Date)

# Print the first few rows
head(df)


barplot(table(df$Domestic))

cat("density plot for crime rate based on lattitude and longitude\n")

geospatial_data <- df %>%
  filter(!is.na(Lat) & !is.na(Lon))
ggplot(geospatial_data, aes(x = Lon, y = Lat)) +
  geom_density2d(color = "blue", size = 0.3) + 
  geom_point(alpha = 0.2, color = "red") +     
  stat_density2d(aes(fill = ..level..), geom = "polygon", alpha = 0.4) +  
  scale_fill_viridis_c(option = "C") +          
  labs(
    title = "Crime Density by Location",
    x = "Longitude",
    y = "Latitude",
    fill = "Density"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )

byvp <- table(df$VP)
pie(byvp,main = "Violent Property of Crime",cex.main = 2, cex = 1.5,labels = paste0(names(byvp), " (", byvp, ")"))

bycat <- sort(table(df$Cat))
par(mar = c(5, 15, 4, 2))
barplot(bycat,horiz = TRUE,main = "Classification of Crimes",  xlab = "Number of Crimes",cex.names = 0.8,cex.main = 2, border = "black",las = 1)



bymonth <- df %>%
  mutate(Date = as.Date(Date)) %>%
  group_by(Month = floor_date(Date, "month")) %>%
  summarise(Tot_Inc = sum(Tot_Inc, na.rm = TRUE)) %>%
  mutate(MOY = month(Month, label = TRUE, abbr = TRUE))  # Get abbreviated month names

# Create a boxplot
ggplot(bymonth, aes(x = MOY, y = Tot_Inc)) +
  geom_boxplot(
    width = 0.6,
    linewidth = 1.2,
    fill = "gold",
    color = "black",
    outlier.shape = NA
  ) +
  labs(
    title = "Crime by Months of a Year",
    x = "Months of a Year",
    y = "Number of Crimes"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15)
  )


byday <- df %>%
  mutate(Date = as.Date(Date)) %>%
  group_by(Day = floor_date(Date, "day")) %>%
  summarise(Tot_Inc = sum(Tot_Inc, na.rm = TRUE)) %>%
  mutate(DOW = wday(Day, label = TRUE, abbr = TRUE, week_start = 1))  # Get day names, Mon-Sun

# Create a boxplot
ggplot(byday, aes(x = DOW, y = Tot_Inc)) +
  geom_boxplot(
    width = 0.6,
    linewidth = 1.2,
    fill = "limegreen",
    color = "black",
    outlier.shape = NA
  ) +
  labs(
    title = "Crime by Days of a Week",
    x = "Days of a Week",
    y = "Number of Crimes"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15)
  )


df <- df %>%
  mutate(Time = as.POSIXct(Time, format = "%H:%M:%S"))  # Adjust format to match your data

# Resample data to 60-minute intervals and sum the incidents
bytime <- df %>%
  group_by(Time = floor_date(Time, "hour")) %>%
  summarise(Tot_Inc = sum(Tot_Inc, na.rm = TRUE))

# Plot the line chart with shaded area
ggplot(bytime, aes(x = Time, y = Tot_Inc)) +
  geom_line(color = "black", size = 1) +
  geom_area(aes(y = Tot_Inc), fill = "black", alpha = 0.3) +
  labs(
    title = "Crime Throughout a Day",
    x = "Time of a Day",
    y = "Number of Crimes"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),
    axis.text.y = element_text(size = 12)
  )


df$Date <- as.Date(df$Date)

# Monthly Time Series
monthly_data <- aggregate(Tot_Inc ~ format(Date, "%Y-%m"), data = df, FUN = sum)
start_month <- c(as.numeric(substr(monthly_data[1, 1], 1, 4)), as.numeric(substr(monthly_data[1, 1], 6, 7)))
ts_monthly <- ts(monthly_data$Tot_Inc, start = start_month, frequency = 12)
plot(ts_monthly, main="Number of crimes by months")

# Weekly Time Series
weekly_data <- aggregate(Tot_Inc ~ format(Date, "%Y-%U"), data = df, FUN = sum)
start_week <- c(as.numeric(substr(weekly_data[1, 1], 1, 4)), as.numeric(substr(weekly_data[1, 1], 6, 7)))
ts_weekly <- ts(weekly_data$Tot_Inc, start = start_week, frequency = 52)
plot(ts_weekly, main="Number of crimes by weeks")

# Daily Time Series
daily_data <- aggregate(Tot_Inc ~ Date, data = df, FUN = sum)
start_day <- c(as.numeric(format(daily_data$Date[1], "%Y")), as.numeric(format(daily_data$Date[1], "%j")))
ts_daily <- ts(daily_data$Tot_Inc, start = start_day, frequency = 365)
plot(ts_daily, main="Number of crimes by days")

Acf(ts_monthly)
cat(" There appears to be seasonality in the time series, indicating the increase of crime in specific days.")

h=12

naive_forecast <- naive(ts_monthly , h)
plot(naive_forecast , main = "Naive Forecast")
mtext("Forecast assumes future values equal the last observed value", side = 1, line = 4)

plot(naive_forecast$residuals , main = "Naive Forecast-residuals")
cat("The residuals are  randomly distributed, shows no pattern. This means that the Naive forecast is being able to capture the seasonality and trend\n")

hist(naive_forecast$residuals, main = "Histogram of Naive Forecast Residuals")
cat("Since the histogram is normal, it means that the Naive Forecast might  be a good method in this case.\n")
plot(naive_forecast$fitted, main = "Fitted Values vs Residuals")
lines(naive_forecast$residuals, col = "red")
plot(naive_forecast, main = "Actual vs Residuals")
lines(naive_forecast$residuals, col = "red")

Acf(naive_forecast$residuals, main = "ACF of Naive Forecast Residuals")



mean_forecast <- meanf(ts_monthly , h)
plot(mean_forecast , main = "Mean Forecast")
cat("Forecast assumes future values equal the mean of past values.\n")

plot(mean_forecast$residuals, main = "Mean Forecast Residuals")
hist(mean_forecast$residuals, main = "Histogram of Mean Forecast Residuals")
plot(mean_forecast$fitted, main = "Fitted Values vs Residuals")
lines(mean_forecast$residuals, col = "red")
Acf(mean_forecast$residuals, main = "ACF of Mean Forecast Residuals")
cat("Observing the residuals, we can say  the Mean Forecast doesnot effectively captures the pattern. Since the existence of patterns in residuals, it suggest the models limitations.\n")


Holt_Winters_forecast <- HoltWinters(ts_monthly)
forecast_HW <- forecast(Holt_Winters_forecast , h)
plot(forecast_HW , main = "Holt Winters without drift Forecast")
mtext("Captures both trend and seasonality",  side = 1, line = 4)

plot(forecast_HW$residuals, main = "Holt-Winters Forecast Residuals")
hist(forecast_HW$residuals, main = "Histogram of Holt-Winters Forecast Residuals")
plot(forecast_HW$fitted, main = "Fitted Values vs Residuals")
lines(forecast_HW$residuals, col = "red")
Acf(forecast_HW$residuals, main = "ACF of Holt-Winters Forecast Residuals")
cat(" Since the residuals do not show patterns, this suggests that the model is  capturing the seasonality or trend.\n")


Holt_Winters_drift_forecast <- HoltWinters(ts_monthly )
forecast_HW_drift <- forecast(Holt_Winters_drift_forecast , , drift = TRUE , h)
plot(forecast_HW_drift , main = "Holt Winters with drift Forecast")
mtext("Accounts for trend changes over time with drift", side = 1, line = 4)

plot(forecast_HW_drift$residuals, main = "Holt-Winters with Drift Forecast Residuals")
hist(forecast_HW_drift$residuals, main = "Histogram of Holt-Winters with Drift Residuals")
plot(forecast_HW_drift$fitted, main = "Fitted Values vs Residuals")
lines(forecast_HW_drift$residuals, col = "red")
Acf(forecast_HW_drift$residuals, main = "ACF of Holt-Winters with Drift Residuals")
cat("Similar to the one without drift , residuals are randomly distributed; absence of patterns suggest no accounted trends or seasonality.\n")


ses_forecast <- ses(ts_monthly, h)
plot(ses_forecast)
cat("SES can be effective because it uses a weighted average of past values, putting more weight on recent observations without explicitly modeling trend or seasonality.\n")


MA3_forecast <- ma(ts_monthly, order=3)
MA6_forecast <- ma(ts_monthly, order=6)
MA9_forecast <- ma(ts_monthly, order=9)
plot(ts_monthly)
lines(MA3_forecast, col="red")
lines(MA6_forecast, col="blue")
lines(MA9_forecast, col="green")

stl_decomp_ts_monthly <- stl(ts_monthly, s.window = "periodic")
plot(stl_decomp_ts_monthly, main = "STL Decomposition of Monthly Crimes")

seasonally_adjusted <- seasadj(stl_decomp_ts_monthly)
plot(ts_monthly, type = "l", col = "black", lwd = 2, main = "Original and Seasonally Adjusted monthly crime")
lines(seasonally_adjusted, col = "red", lwd = 2)
legend("topright", legend = c("Original", "Seasonally Adjusted"), col = c("black", "red"), lty = 1)

cat(" Since there is a significant overlap between the original timeseries and seasonally independent timeseries, seasonality is not very pronounced. Factors like trend or randomness moght have bigger influence on the data.\n")
forecast_stl_ts_monthly <- forecast(stl_decomp_ts_monthly, h = 30)
plot(forecast_stl_ts_monthly, main = "Forecasted monthly crime")


ets_decomp_ts_monthly <- ets(ts_monthly)
plot(ets_decomp_ts_monthly)


plot(ts_monthly, main = "Monthly Crime", xlab = "Year", ylab = "Crime")
ndiffs_required_ts_monthly <- ndiffs(ts_monthly)
print(paste("Number of differences required for stationarity:", ndiffs_required_ts_monthly))
tsdisplay(ts_monthly, main = "Original Time Series: Monthly Crime")
ts_monthly_diff1 <- diff(ts_monthly, differences = 1)
plot(ts_monthly_diff1, main = "First-Order Differenced: Monthly Crime", ylab = "Differenced Values")
tsdisplay(ts_monthly_diff1, main = "ACF and PACF: Differenced Monthly Crime")

ts_monthly_arima_model <- auto.arima(ts_monthly, trace = TRUE, seasonal = TRUE, stepwise = FALSE)
summary(ts_monthly_arima_model)
cat("The ARIMA(2,1,1)(0,0,2)[12] model indicates a seasonal ARIMA with two autoregressive terms (AR), one differencing step (I), and one moving average term (MA), alongside two seasonal moving average terms (sMA) for monthly data. The coefficients provide weights for these components, with associated standard errors indicating the uncertainty of each estimate. Key model evaluation metrics include AIC (3170.87), AICc (3171.16), and BIC (3193.08), where lower values indicate better fit while penalizing complexity. Training set error measures such as RMSE (47.39) and MAE (34.60) highlight the average prediction errors. MAPE (8.85%) reflects a reasonably accurate model, with residuals showing minimal autocorrelation (ACF1 = 0.056), suggesting a good fit for the data with little remaining structure in the errors.\n")

ts_monthly_arima_forecast <- forecast(ts_monthly_arima_model, h = 12)
plot(ts_monthly_arima_forecast, main = "Monthly Crime Rate Forecast")

ts_monthly_arima_residuals <- residuals(ts_monthly_arima_model)

# Plot Residuals
par(mfrow = c(2, 2)) # Set up a 2x2 plotting layout
plot(ts_monthly_arima_residuals, main = "Residuals of ARIMA Model", ylab = "Residuals", col = "blue")
abline(h = 0, col = "red", lty = 2)

cat("The randomness in the residuals suggest a good fit.")

# Histogram of Residuals
hist(ts_monthly_arima_residuals, main = "Histogram of ARIMA Residuals", col = "skyblue", xlab = "Residuals")

# ACF of Residuals
Acf(ts_monthly_arima_residuals, main = "ACF of ARIMA Residuals")

# Ljung-Box Test for Residuals
ljung_box_test <- Box.test(ts_monthly_arima_residuals, lag = 20, type = "Ljung-Box")
print("Ljung-Box Test Results:")
print(ljung_box_test)
cat("The residuals do not show significant autocorrelation, indicating that the ARIMA model has captured the dependencies in the data well, and no major patterns remain unexplained.\n")

# Residual Statistics
residual_stats_arima <- data.frame(
  Metric = c("Mean", "Variance", "Standard Deviation"),
  Value = c(mean(ts_monthly_arima_residuals), var(ts_monthly_arima_residuals), sd(ts_monthly_arima_residuals))
)
print("Residual Statistics:")
print(residual_stats_arima)

# Clean up plotting layout
par(mfrow = c(1, 1))

fitted_arima_values <- fitted(ts_monthly_arima_model)

# Plot Observed vs Predicted
plot(ts_monthly, col = "blue", lwd = 2, 
     main = "Observed vs Predicted: ARIMA(2,1,1)(0,0,2)[12]",
     ylab = "Monthly Crime", xlab = "Time")
lines(fitted_arima_values, col = "red", lwd = 2)

# Add legend
legend("topleft", legend = c("Observed", "Predicted"), 
       col = c("blue", "red"), lty = c(1, 1), lwd = c(2, 2), bty = "n")


# Use the forecast object residuals and built-in functions
naive_rmse <- sqrt(mean(naive_forecast$residuals^2, na.rm = TRUE))
ses_rmse <- sqrt(mean(ses_forecast$residuals^2, na.rm = TRUE))
hw_rmse <- sqrt(mean(forecast_HW$residuals^2, na.rm = TRUE))

# Moving average forecasts
ma3_rmse <- sqrt(mean((ts_monthly - MA3_forecast)^2, na.rm = TRUE))
ma6_rmse <- sqrt(mean((ts_monthly - MA6_forecast)^2, na.rm = TRUE))
ma9_rmse <- sqrt(mean((ts_monthly - MA9_forecast)^2, na.rm = TRUE))

# Combine into a table
rmse_table <- data.frame(
  Method = c("Naive", "SES", "HW", "MA3", "MA6", "MA9"),
  RMSE = c(naive_rmse, ses_rmse, hw_rmse, ma3_rmse, ma6_rmse, ma9_rmse)
)

# Print RMSE table
print(rmse_table)

```


```{r, echo=FALSE, results='asis'}
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)


# Function to analyze a single crime category
analyze_category <- function(category) {
cat("Processing category:", category, "\n")
  
  # Filter data for the specific category
category_data <- df %>% filter(Cat == category)
  
  # Aggregate incidents by month
monthly_data <- aggregate(Tot_Inc ~ format(Date, "%Y-%m"), data = category_data, FUN = sum)
  
if (nrow(monthly_data) < 24) { cat("Insufficient data for STL decomposition for category:",category, "\n")
return(NULL)
}
  
start_month <- c(as.numeric(substr(monthly_data[1, 1], 1, 4)), as.numeric(substr(monthly_data[1, 1], 6, 7)))
ts_category <- ts(monthly_data$Tot_Inc, start = start_month, frequency = 12)
  
  # 1. Naive Forecast
  naive_forecast <- naive(ts_category, h = 12)
  
  # 2. Mean Forecast
  mean_forecast <- meanf(ts_category, h = 12)
  
  # 3. Holt-Winters Forecast
  holt_winters_forecast <- HoltWinters(ts_category)
  forecast_hw <- forecast(holt_winters_forecast, h = 12)
  
  # 4. STL Decomposition
  stl_decomp <- stl(ts_category, s.window = "periodic")
  forecast_stl <- forecast(stl_decomp, h = 12)
  
  # 5. ARIMA Model
  arima_model <- auto.arima(ts_category, trace = TRUE, seasonal = TRUE)
  arima_forecast <- forecast(arima_model, h = 12)
  
  # Plots for the category
  par(mfrow = c(2, 3)) # Set a 2x3 plot layout
  plot(ts_category, main = paste("Original Data:", category))
  plot(naive_forecast, main = paste("Naive Forecast:", category))
  plot(mean_forecast, main = paste("Mean Forecast:", category))
  plot(forecast_hw, main = paste("Holt-Winters Forecast:", category))
  plot(forecast_stl, main = paste("STL Decomposition Forecast:", category))
  plot(arima_forecast, main = paste("ARIMA Forecast:", category))
  par(mfrow = c(1, 1)) # Reset layout
  # Residual Analysis
  perform_residual_analysis <- function(model_residuals, model_name) {
    par(mfrow = c(2, 2))  # Set a 2x2 layout
    plot(model_residuals, main = paste("Residuals:", category, "-", model_name), ylab = "Residuals", xlab = "Time", col = "blue")
    hist(model_residuals, main = paste("Histogram of Residuals:", category, "-", model_name), col = "skyblue", xlab = "Residuals")
    Acf(model_residuals, main = paste("ACF of Residuals:", category, "-", model_name))
    ljung_box_test <- Box.test(model_residuals, lag = 20, type = "Ljung-Box")
    cat("Ljung-Box Test p-value for", category, "-", model_name, ":", ljung_box_test$p.value, "\n")
    par(mfrow = c(1, 1))  
  }
  
  # Perform residual analysis for each model
  perform_residual_analysis(naive_forecast$residuals, "Naive Forecast")
  perform_residual_analysis(mean_forecast$residuals, "Mean Forecast")
  perform_residual_analysis(forecast_hw$residuals, "Holt-Winters Forecast")
  perform_residual_analysis(arima_forecast$residuals, "ARIMA Forecast")
  
  # Plot STL decomposition residuals separately
  par(mfrow = c(2, 2))  # Set a 2x2 layout for STL residuals
  plot(stl_decomp$time.series[, "remainder"], main = paste("STL Residuals:", category), ylab = "Residuals", xlab = "Time", col = "blue")
  hist(stl_decomp$time.series[, "remainder"], main = paste("Histogram of STL Residuals:", category), col = "skyblue", xlab = "Residuals")
  Acf(stl_decomp$time.series[, "remainder"], main = paste("ACF of STL Residuals:", category))
  ljung_box_stl <- Box.test(stl_decomp$time.series[, "remainder"], lag = 20, type = "Ljung-Box")
  cat("Ljung-Box Test p-value for STL Residuals:", category, ":", ljung_box_stl$p.value, "\n")
  par(mfrow = c(1, 1))  # Reset layout
  
  
  
  # Return results as a list
  return(list(
    ts = ts_category,
    naive = naive_forecast,
    mean = mean_forecast,
    holt_winters = forecast_hw,
    stl = forecast_stl,
    arima = arima_forecast,
    residuals = list(
      naive = naive_forecast$residuals,
      mean = mean_forecast$residuals,
      holt_winters = forecast_hw$residuals,
      stl = stl_decomp$time.series[, "remainder"],
      arima = arima_forecast$residuals
    ),
    ljung_box_p_values = list(
      naive = Box.test(naive_forecast$residuals, lag = 20, type = "Ljung-Box")$p.value,
      mean = Box.test(mean_forecast$residuals, lag = 20, type = "Ljung-Box")$p.value,
      holt_winters = Box.test(forecast_hw$residuals, lag = 20, type = "Ljung-Box")$p.value,
      stl = ljung_box_stl$p.value,
      arima = Box.test(arima_forecast$residuals, lag = 20, type = "Ljung-Box")$p.value
    )
  ))
}

# Get unique categories
unique_categories <- unique(df$Cat)

# Initialize results list for all categories
results <- list()

# Loop through each category
for (category in unique_categories) {
  tryCatch({
    results[[category]] <- analyze_category(category)
  }, error = function(e) {
    cat("Error processing category:", category, "-", e$message, "\n")
  })
}

# Report on results
completed_categories <- names(results)[!sapply(results, is.null)]
failed_categories <- names(results)[sapply(results, is.null)]
cat("Successfully processed categories:", completed_categories, "\n")
cat("Categories with issues:", failed_categories, "\n")


# Display RMSE for each forecast method for all categories
for (category in names(results)) {
  if (!is.null(results[[category]])) {
    cat("\nRMSE for category:", category, "\n")
    
    # Extract forecasts and calculate RMSE
    result <- results[[category]]
    
    if (!is.null(result$naive)) {
      naive_rmse <- sqrt(mean(result$naive$residuals^2, na.rm = TRUE))
      cat("Naive RMSE:", naive_rmse, "\n")
    }
    
    if (!is.null(result$mean)) {
      mean_rmse <- sqrt(mean(result$mean$residuals^2, na.rm = TRUE))
      cat("Mean RMSE:", mean_rmse, "\n")
    }
    
    if (!is.null(result$holt_winters)) {
      hw_rmse <- sqrt(mean(result$holt_winters$residuals^2, na.rm = TRUE))
      cat("Holt-Winters RMSE:", hw_rmse, "\n")
    }
    
    if (!is.null(result$stl)) {
      stl_rmse <- sqrt(mean((result$ts - seasadj(stl(result$ts, s.window = "periodic")))^2, na.rm = TRUE))
      cat("STL RMSE:", stl_rmse, "\n")
    }
    
    if (!is.null(result$arima)) {
      arima_rmse <- sqrt(mean(result$arima$residuals^2, na.rm = TRUE))
      cat("ARIMA RMSE:", arima_rmse, "\n")
    }
  }
}


cat(" Overall, the forecast suggests a slight decline in crime rates in the near future, followed by minor fluctuations. The trend indicates that crime levels are likely to stabilize and remain close to the current levels by the end of the year.\n")

cat("r The RMSE values from different forecasting methods highlight their predictive accuracy for the given time series data. Among the methods, the Moving Average with a window size of 3 (MA3) achieves the lowest RMSE (28.70), suggesting it provides the most accurate forecasts. The Holt-Winters (HW) method also performs well (RMSE: 42.97), capturing trends and seasonality effectively. In contrast, the Naive method has the highest RMSE (55.76), indicating less reliable predictions. These results emphasize the importance of selecting the most suitable method, like MA3, for forecasting in this context.\n")


cat(" Based on the individual forecasts for various crime categories, the analysis reveals distinct trends. Larceny, forgery, drugs, missing person, motor vehicle theft, and stolen property initially show a decrease, with stolen property subsequently increasing. Vandalism, burglary, fraud, weapons offenses, and suicide are projected to rise, albeit at varying rates. Simple assault, alcohol-related offenses, DUI, aggravated assault, arson, embezzlement, and other offenses are expected to remain stable, with minor fluctuations in some cases. Traffic violations, excluding DWI, are predicted to either decline slightly or remain steady. These insights provide a nuanced understanding of potential future trends in crime rates across different categories.\n")

cat(" The RMSE values highlight the accuracy of different forecasting methods, with lower values indicating better performance. STL decomposition consistently achieves the lowest RMSE across most categories, making it the most reliable method, particularly for crimes like Larceny, Vandalism, and Forgery. ARIMA and Holt-Winters also perform well in capturing trends and seasonality, while Naive and Mean forecasts generally have higher RMSE, indicating lower accuracy. These comparisons guide the selection of effective models for forecasting crime trends.\n")

```



```{r, echo=FALSE, results='asis'}
regression_model <- lm(Lon ~ Lat, data = df)

# Summary of the regression model
summary(regression_model)
cat(" The regression model shows a significant relationship between latitude and longitude, with an R-squared of 22.35%, indicating that 22.35% of longitude variance is explained by latitude. The coefficients are highly significant (p < 2.2e-16), and the residual standard error is low (0.03845), suggesting a strong but not comprehensive fit.")
# Create a scatter plot with regression line
ggplot(df, aes(x = Lat, y = Lon)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(
    title = "Linear Regression: Longitude vs Latitude",
    x = "Latitude",
    y = "Longitude"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )
cat(" Here is performing simple regression on lattitude and longitude, since the dataset has a lot of categoriacal data, regression might not be a best strategy, however the linear regression model predicts the longitude (Lon) based on the latitude (Lat) of crime incidents. The scatter plot visualizes the relationship between Lat and Lon, with the regression line (in red) showing the best fit. The summary of the regression model includes coefficients, their significance, and overall model metrics, providing insights into the spatial distribution of crimes.")

```


